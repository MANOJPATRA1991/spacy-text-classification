{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "import re\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from spacy.lang.en import English\n",
    "import en_core_web_lg\n",
    "from  spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.matcher import PhraseMatcher\n",
    "import json\n",
    "import math\n",
    "import string\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_url(initialCount, sentiment):\n",
    "    return \"https://apidev.weavr.ai/api/conversations?excludeConversationsWithMissingBio=false&includeText=true&excludeRetweet=true&from={0}&size=1000&sources[]=Blogs&sources[]=Github-Issue&sources[]=Gitter-messages&sources[]=Hackernews&sources[]=Lobster-Stories&sources[]=LowEndTalk&sources[]=Medium&sources[]=Reddit&sources[]=StackOverflow&sources[]=Twitter&onlyBug=false&onlyFeatureRequest=false&onlyFromCompanies=false&exclude=false&sort=-time&startDate=2019-07-02T09:18:42.872Z&endDate=2019-07-09T09:18:42.872Z&sentiments[]={1}\".format(initialCount, sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = { 'results': [] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# spacy.require_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://apidev.weavr.ai/api/conversations?excludeConversationsWithMissingBio=false&includeText=true&excludeRetweet=true&from=0&size=1000&sources[]=Blogs&sources[]=Github-Issue&sources[]=Gitter-messages&sources[]=Hackernews&sources[]=Lobster-Stories&sources[]=LowEndTalk&sources[]=Medium&sources[]=Reddit&sources[]=StackOverflow&sources[]=Twitter&onlyBug=false&onlyFeatureRequest=false&onlyFromCompanies=false&exclude=false&sort=-time&startDate=2019-07-16T09:18:42.872Z&endDate=2019-07-23T09:18:42.872Z&sentiments[]=negative\n",
      "0 60000\n",
      "https://apidev.weavr.ai/api/conversations?excludeConversationsWithMissingBio=false&includeText=true&excludeRetweet=true&from=1000&size=1000&sources[]=Blogs&sources[]=Github-Issue&sources[]=Gitter-messages&sources[]=Hackernews&sources[]=Lobster-Stories&sources[]=LowEndTalk&sources[]=Medium&sources[]=Reddit&sources[]=StackOverflow&sources[]=Twitter&onlyBug=false&onlyFeatureRequest=false&onlyFromCompanies=false&exclude=false&sort=-time&startDate=2019-07-16T09:18:42.872Z&endDate=2019-07-23T09:18:42.872Z&sentiments[]=negative\n",
      "1 61000\n",
      "https://apidev.weavr.ai/api/conversations?excludeConversationsWithMissingBio=false&includeText=true&excludeRetweet=true&from=2000&size=1000&sources[]=Blogs&sources[]=Github-Issue&sources[]=Gitter-messages&sources[]=Hackernews&sources[]=Lobster-Stories&sources[]=LowEndTalk&sources[]=Medium&sources[]=Reddit&sources[]=StackOverflow&sources[]=Twitter&onlyBug=false&onlyFeatureRequest=false&onlyFromCompanies=false&exclude=false&sort=-time&startDate=2019-07-16T09:18:42.872Z&endDate=2019-07-23T09:18:42.872Z&sentiments[]=negative\n",
      "2 62000\n",
      "https://apidev.weavr.ai/api/conversations?excludeConversationsWithMissingBio=false&includeText=true&excludeRetweet=true&from=3000&size=1000&sources[]=Blogs&sources[]=Github-Issue&sources[]=Gitter-messages&sources[]=Hackernews&sources[]=Lobster-Stories&sources[]=LowEndTalk&sources[]=Medium&sources[]=Reddit&sources[]=StackOverflow&sources[]=Twitter&onlyBug=false&onlyFeatureRequest=false&onlyFromCompanies=false&exclude=false&sort=-time&startDate=2019-07-16T09:18:42.872Z&endDate=2019-07-23T09:18:42.872Z&sentiments[]=negative\n",
      "3 63000\n",
      "https://apidev.weavr.ai/api/conversations?excludeConversationsWithMissingBio=false&includeText=true&excludeRetweet=true&from=4000&size=1000&sources[]=Blogs&sources[]=Github-Issue&sources[]=Gitter-messages&sources[]=Hackernews&sources[]=Lobster-Stories&sources[]=LowEndTalk&sources[]=Medium&sources[]=Reddit&sources[]=StackOverflow&sources[]=Twitter&onlyBug=false&onlyFeatureRequest=false&onlyFromCompanies=false&exclude=false&sort=-time&startDate=2019-07-16T09:18:42.872Z&endDate=2019-07-23T09:18:42.872Z&sentiments[]=negative\n",
      "4 64000\n",
      "https://apidev.weavr.ai/api/conversations?excludeConversationsWithMissingBio=false&includeText=true&excludeRetweet=true&from=5000&size=1000&sources[]=Blogs&sources[]=Github-Issue&sources[]=Gitter-messages&sources[]=Hackernews&sources[]=Lobster-Stories&sources[]=LowEndTalk&sources[]=Medium&sources[]=Reddit&sources[]=StackOverflow&sources[]=Twitter&onlyBug=false&onlyFeatureRequest=false&onlyFromCompanies=false&exclude=false&sort=-time&startDate=2019-07-16T09:18:42.872Z&endDate=2019-07-23T09:18:42.872Z&sentiments[]=negative\n",
      "5 65000\n",
      "https://apidev.weavr.ai/api/conversations?excludeConversationsWithMissingBio=false&includeText=true&excludeRetweet=true&from=6000&size=1000&sources[]=Blogs&sources[]=Github-Issue&sources[]=Gitter-messages&sources[]=Hackernews&sources[]=Lobster-Stories&sources[]=LowEndTalk&sources[]=Medium&sources[]=Reddit&sources[]=StackOverflow&sources[]=Twitter&onlyBug=false&onlyFeatureRequest=false&onlyFromCompanies=false&exclude=false&sort=-time&startDate=2019-07-16T09:18:42.872Z&endDate=2019-07-23T09:18:42.872Z&sentiments[]=negative\n",
      "6 66000\n",
      "https://apidev.weavr.ai/api/conversations?excludeConversationsWithMissingBio=false&includeText=true&excludeRetweet=true&from=7000&size=1000&sources[]=Blogs&sources[]=Github-Issue&sources[]=Gitter-messages&sources[]=Hackernews&sources[]=Lobster-Stories&sources[]=LowEndTalk&sources[]=Medium&sources[]=Reddit&sources[]=StackOverflow&sources[]=Twitter&onlyBug=false&onlyFeatureRequest=false&onlyFromCompanies=false&exclude=false&sort=-time&startDate=2019-07-16T09:18:42.872Z&endDate=2019-07-23T09:18:42.872Z&sentiments[]=negative\n",
      "7 67000\n",
      "https://apidev.weavr.ai/api/conversations?excludeConversationsWithMissingBio=false&includeText=true&excludeRetweet=true&from=8000&size=1000&sources[]=Blogs&sources[]=Github-Issue&sources[]=Gitter-messages&sources[]=Hackernews&sources[]=Lobster-Stories&sources[]=LowEndTalk&sources[]=Medium&sources[]=Reddit&sources[]=StackOverflow&sources[]=Twitter&onlyBug=false&onlyFeatureRequest=false&onlyFromCompanies=false&exclude=false&sort=-time&startDate=2019-07-16T09:18:42.872Z&endDate=2019-07-23T09:18:42.872Z&sentiments[]=negative\n",
      "8 68000\n",
      "https://apidev.weavr.ai/api/conversations?excludeConversationsWithMissingBio=false&includeText=true&excludeRetweet=true&from=9000&size=1000&sources[]=Blogs&sources[]=Github-Issue&sources[]=Gitter-messages&sources[]=Hackernews&sources[]=Lobster-Stories&sources[]=LowEndTalk&sources[]=Medium&sources[]=Reddit&sources[]=StackOverflow&sources[]=Twitter&onlyBug=false&onlyFeatureRequest=false&onlyFromCompanies=false&exclude=false&sort=-time&startDate=2019-07-16T09:18:42.872Z&endDate=2019-07-23T09:18:42.872Z&sentiments[]=negative\n",
      "9 69000\n",
      "https://apidev.weavr.ai/api/conversations?excludeConversationsWithMissingBio=false&includeText=true&excludeRetweet=true&from=10000&size=1000&sources[]=Blogs&sources[]=Github-Issue&sources[]=Gitter-messages&sources[]=Hackernews&sources[]=Lobster-Stories&sources[]=LowEndTalk&sources[]=Medium&sources[]=Reddit&sources[]=StackOverflow&sources[]=Twitter&onlyBug=false&onlyFeatureRequest=false&onlyFromCompanies=false&exclude=false&sort=-time&startDate=2019-07-16T09:18:42.872Z&endDate=2019-07-23T09:18:42.872Z&sentiments[]=negative\n",
      "10 69000\n",
      "https://apidev.weavr.ai/api/conversations?excludeConversationsWithMissingBio=false&includeText=true&excludeRetweet=true&from=11000&size=1000&sources[]=Blogs&sources[]=Github-Issue&sources[]=Gitter-messages&sources[]=Hackernews&sources[]=Lobster-Stories&sources[]=LowEndTalk&sources[]=Medium&sources[]=Reddit&sources[]=StackOverflow&sources[]=Twitter&onlyBug=false&onlyFeatureRequest=false&onlyFromCompanies=false&exclude=false&sort=-time&startDate=2019-07-16T09:18:42.872Z&endDate=2019-07-23T09:18:42.872Z&sentiments[]=negative\n",
      "11 69000\n",
      "https://apidev.weavr.ai/api/conversations?excludeConversationsWithMissingBio=false&includeText=true&excludeRetweet=true&from=12000&size=1000&sources[]=Blogs&sources[]=Github-Issue&sources[]=Gitter-messages&sources[]=Hackernews&sources[]=Lobster-Stories&sources[]=LowEndTalk&sources[]=Medium&sources[]=Reddit&sources[]=StackOverflow&sources[]=Twitter&onlyBug=false&onlyFeatureRequest=false&onlyFromCompanies=false&exclude=false&sort=-time&startDate=2019-07-16T09:18:42.872Z&endDate=2019-07-23T09:18:42.872Z&sentiments[]=negative\n",
      "12 69000\n",
      "https://apidev.weavr.ai/api/conversations?excludeConversationsWithMissingBio=false&includeText=true&excludeRetweet=true&from=13000&size=1000&sources[]=Blogs&sources[]=Github-Issue&sources[]=Gitter-messages&sources[]=Hackernews&sources[]=Lobster-Stories&sources[]=LowEndTalk&sources[]=Medium&sources[]=Reddit&sources[]=StackOverflow&sources[]=Twitter&onlyBug=false&onlyFeatureRequest=false&onlyFromCompanies=false&exclude=false&sort=-time&startDate=2019-07-16T09:18:42.872Z&endDate=2019-07-23T09:18:42.872Z&sentiments[]=negative\n",
      "13 69000\n",
      "https://apidev.weavr.ai/api/conversations?excludeConversationsWithMissingBio=false&includeText=true&excludeRetweet=true&from=14000&size=1000&sources[]=Blogs&sources[]=Github-Issue&sources[]=Gitter-messages&sources[]=Hackernews&sources[]=Lobster-Stories&sources[]=LowEndTalk&sources[]=Medium&sources[]=Reddit&sources[]=StackOverflow&sources[]=Twitter&onlyBug=false&onlyFeatureRequest=false&onlyFromCompanies=false&exclude=false&sort=-time&startDate=2019-07-16T09:18:42.872Z&endDate=2019-07-23T09:18:42.872Z&sentiments[]=negative\n",
      "14 69000\n",
      "https://apidev.weavr.ai/api/conversations?excludeConversationsWithMissingBio=false&includeText=true&excludeRetweet=true&from=15000&size=1000&sources[]=Blogs&sources[]=Github-Issue&sources[]=Gitter-messages&sources[]=Hackernews&sources[]=Lobster-Stories&sources[]=LowEndTalk&sources[]=Medium&sources[]=Reddit&sources[]=StackOverflow&sources[]=Twitter&onlyBug=false&onlyFeatureRequest=false&onlyFromCompanies=false&exclude=false&sort=-time&startDate=2019-07-16T09:18:42.872Z&endDate=2019-07-23T09:18:42.872Z&sentiments[]=negative\n",
      "15 69000\n",
      "https://apidev.weavr.ai/api/conversations?excludeConversationsWithMissingBio=false&includeText=true&excludeRetweet=true&from=16000&size=1000&sources[]=Blogs&sources[]=Github-Issue&sources[]=Gitter-messages&sources[]=Hackernews&sources[]=Lobster-Stories&sources[]=LowEndTalk&sources[]=Medium&sources[]=Reddit&sources[]=StackOverflow&sources[]=Twitter&onlyBug=false&onlyFeatureRequest=false&onlyFromCompanies=false&exclude=false&sort=-time&startDate=2019-07-16T09:18:42.872Z&endDate=2019-07-23T09:18:42.872Z&sentiments[]=negative\n",
      "16 69000\n",
      "https://apidev.weavr.ai/api/conversations?excludeConversationsWithMissingBio=false&includeText=true&excludeRetweet=true&from=17000&size=1000&sources[]=Blogs&sources[]=Github-Issue&sources[]=Gitter-messages&sources[]=Hackernews&sources[]=Lobster-Stories&sources[]=LowEndTalk&sources[]=Medium&sources[]=Reddit&sources[]=StackOverflow&sources[]=Twitter&onlyBug=false&onlyFeatureRequest=false&onlyFromCompanies=false&exclude=false&sort=-time&startDate=2019-07-16T09:18:42.872Z&endDate=2019-07-23T09:18:42.872Z&sentiments[]=negative\n",
      "17 69000\n",
      "https://apidev.weavr.ai/api/conversations?excludeConversationsWithMissingBio=false&includeText=true&excludeRetweet=true&from=18000&size=1000&sources[]=Blogs&sources[]=Github-Issue&sources[]=Gitter-messages&sources[]=Hackernews&sources[]=Lobster-Stories&sources[]=LowEndTalk&sources[]=Medium&sources[]=Reddit&sources[]=StackOverflow&sources[]=Twitter&onlyBug=false&onlyFeatureRequest=false&onlyFromCompanies=false&exclude=false&sort=-time&startDate=2019-07-16T09:18:42.872Z&endDate=2019-07-23T09:18:42.872Z&sentiments[]=negative\n",
      "18 69000\n",
      "https://apidev.weavr.ai/api/conversations?excludeConversationsWithMissingBio=false&includeText=true&excludeRetweet=true&from=19000&size=1000&sources[]=Blogs&sources[]=Github-Issue&sources[]=Gitter-messages&sources[]=Hackernews&sources[]=Lobster-Stories&sources[]=LowEndTalk&sources[]=Medium&sources[]=Reddit&sources[]=StackOverflow&sources[]=Twitter&onlyBug=false&onlyFeatureRequest=false&onlyFromCompanies=false&exclude=false&sort=-time&startDate=2019-07-16T09:18:42.872Z&endDate=2019-07-23T09:18:42.872Z&sentiments[]=negative\n",
      "19 69000\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "sentiment = ['positive', 'negative', 'neutral']\n",
    "\n",
    "while count < 9:\n",
    "    print(create_url(math.floor(count / 3)*1000, sentiment[count % 3]))\n",
    "\n",
    "    headers = {'authorization': 'Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImtpZCI6IlF6SXlRMFF4UlRNMlJrSkNRek14UVVOQlFqSXlRVFUyUmtZeFJFWkZOekpEUmtZeFJVRkROdyJ9.eyJpc3MiOiJodHRwczovL3dlYXZyLWRldi5hdXRoMC5jb20vIiwic3ViIjoiYXV0aDB8NWQ2MzY2NjIxMjg2YjEwZGYyOTI2MWNjIiwiYXVkIjpbImh0dHBzOi8vYXBpZGV2LndlYXZyLmFpIiwiaHR0cHM6Ly93ZWF2ci1kZXYuYXV0aDAuY29tL3VzZXJpbmZvIl0sImlhdCI6MTU2Njk4NDc5MSwiZXhwIjoxNTY3MDQ5NTkxLCJhenAiOiJlcnYyRGV6NUJ2M3V4NDVna1pseGFpaTVWUDdZRHJ0TCIsInNjb3BlIjoib3BlbmlkIHByb2ZpbGUifQ.md2N3OPUFyfcW5rkkF9umTXK5EoJGyRlokiR_gNZ10-0GGZRuKriLOg22a-SpgggRUpcZs-44lJQJv0ezrXoIHE4TzKJDwG9pqaY9A3jijzgDgIQf0jOvhv63ceKEOSnZMVehKEvz3faed7wx2RDwoo2ZAF0tHXa7mb5XmR4kA-bkSn9-aCs0hKAnjw7Bp374buNnmECqL9orqsfoK1kdoNaD7r989KQJu1W_DN2xi0mlvaUQnhA7GNRq1dEQLR9gd6bboAf_tVRDQkAex8jANtclcKIVIDZ16ICZitUfXpaJG9V3L0hiGisO2M-We9kacOd8sUOJdd1ZDcbASX8Kw'}\n",
    "    response = requests.get(create_url(math.floor(count / 3)*1000, sentiment[count % 3]), headers=headers)\n",
    "\n",
    "    data = json.loads(response.text)\n",
    "\n",
    "    with open('new_posts.txt') as json_file:\n",
    "        new_data = json.load(json_file)\n",
    "\n",
    "    new_data['results'] = new_data['results'] + data['results']\n",
    "\n",
    "    with open('new_posts.txt', 'w') as out_file:\n",
    "        json.dump(new_data, out_file)\n",
    "\n",
    "    print(count, len(new_data['results']))\n",
    "    \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(STOP_WORDS)\n",
    "punctuations = string.punctuation.replace(\"#\", \"\")\n",
    "parser = English()\n",
    "nlp = en_core_web_lg.load()\n",
    "# Stemming\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenizer(sentence):\n",
    "    tokens = parser(sentence)\n",
    "    # Lower case all words and strip white spaces\n",
    "    tokens = [word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in tokens]\n",
    "    # Remove all stop words and punctuations\n",
    "    tokens = [word for word in tokens if word not in stopwords and word not in punctuations]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "    return input_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'late logan marktag daily #ad cloud analytics thanks'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_sentence(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    # Token matchers\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    \n",
    "    # Create matcher to detect urls\n",
    "    pattern = [{ \"LIKE_URL\": True }]\n",
    "    matcher.add(\"UrlDetection\", None, pattern)\n",
    "    \n",
    "    # Create matcher to detect ...\n",
    "    pattern = [{ \"TEXT\": \"...\" }]\n",
    "    matcher.add(\"MoreDotsDetection\", None, pattern)\n",
    "\n",
    "    matches = matcher(doc)\n",
    "    \n",
    "    for match_id, start, end in matches:\n",
    "        string_id = nlp.vocab.strings[match_id]\n",
    "        span = doc[start:end]\n",
    "        sentence = sentence.replace(span.text, '')\n",
    "    \n",
    "    sentence = remove_tags(sentence)\n",
    "    \n",
    "    # Tokenize sentence and join\n",
    "    sentence = ' '.join(str(token) for token in spacy_tokenizer(sentence))\n",
    "    \n",
    "    # Remove twitter handles\n",
    "    sentence = remove_pattern(sentence, \"@[\\w]*\")\n",
    "    \n",
    "    sentence = '#'.join([phrase for phrase in [e[1:] for e in (' ' + sentence).split(\"#\")]])\n",
    "\n",
    "    # remove words with length less than 3 and not #\n",
    "    sentence = ' '.join([word for word in sentence.split() if word[0] == '#' or len(word)>3])\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "clean_sentence(\"The latest Logan's <mark>marktag</mark> DX Daily #AD (Cloud, AI/ML, Analytics & IoT)! https://t.co/Ac3cKz73Gx Thanks to @JD_Corporate... https://t.co/OOyzLIPxA2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In order to make the public truly feel the changes that future #AI may bring to our lives, two free exhibitions fea... https://t.co/qYe2NVc6vc', 'The latest DIY-Not?! https://t.co/kPgjCyManF Thanks to @pi_stack @stem_nastics @zoobab #raspberrypi #arduino', 'Techinflo, leading #Angular Development Company inspires you to outsource certain processes for multiple associated... https://t.co/MipzQW3MCw', 'Playlist:\\nBlurry - kookheon yuvin\\nBegin again - kim jaehwan\\nWith laugh or with tears - seo in guk\\nPlease dont - k w... https://t.co/SRcyuf5Nh8', 'Now playing STREET ORPHAN - LETHAL dl the app google play &amp; ios be apart of the movement also TUNE IN LIVE \\nFRI &amp; SAT 8PM -12AM']\n"
     ]
    }
   ],
   "source": [
    "with open('new_posts.txt', encoding=\"utf-8\") as json_file:\n",
    "    new_data = json.load(json_file)\n",
    "    \n",
    "new_data = [result['title'] for result in new_data['results']]\n",
    "\n",
    "print(new_data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=('Text', 'Label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(texts):\n",
    "    tw = []\n",
    "    pl = []\n",
    "\n",
    "    for text in texts:\n",
    "        text = clean_sentence(text)\n",
    "        str(text)\n",
    "        sent  = TextBlob(text)\n",
    "        tw.append(text)\n",
    "        pl.append(sent.sentiment.polarity)\n",
    "\n",
    "    df['Text'] = tw\n",
    "    df['Label'] = pl\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69000, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_df(new_data)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>order public truly feel change future #ai brin...</td>\n",
       "      <td>0.134091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>late thanks #raspberrypi #arduino</td>\n",
       "      <td>-0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>techinflo lead #angular development company in...</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>playlist blurry kookheon yuvin begin jaehwan l...</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>play street orphan lethal google play apart mo...</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Label\n",
       "0  order public truly feel change future #ai brin...  0.134091\n",
       "1                  late thanks #raspberrypi #arduino -0.050000\n",
       "2  techinflo lead #angular development company in...  0.107143\n",
       "3  playlist blurry kookheon yuvin begin jaehwan l...  0.300000\n",
       "4  play street orphan lethal google play apart mo...  0.136364"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_type(num):\n",
    "    if (num >= -1 and num < 0):\n",
    "        return 'NEGATIVE'\n",
    "    elif (num > 0 and num <= 1):\n",
    "        return 'POSITIVE'\n",
    "    else:\n",
    "        return 'NEUTRAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'] = df['Label'].apply(lambda x: sentiment_type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>order public truly feel change future #ai brin...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>late thanks #raspberrypi #arduino</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>techinflo lead #angular development company in...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>playlist blurry kookheon yuvin begin jaehwan l...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>play street orphan lethal google play apart mo...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Label\n",
       "0  order public truly feel change future #ai brin...  POSITIVE\n",
       "1                  late thanks #raspberrypi #arduino  NEGATIVE\n",
       "2  techinflo lead #angular development company in...  POSITIVE\n",
       "3  playlist blurry kookheon yuvin begin jaehwan l...  POSITIVE\n",
       "4  play street orphan lethal google play apart mo...  POSITIVE"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>order public truly feel change future #ai brin...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>techinflo lead #angular development company in...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>playlist blurry kookheon yuvin begin jaehwan l...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>play street orphan lethal google play apart mo...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>blessed cake welcome heaven like play death da...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Label\n",
       "0  order public truly feel change future #ai brin...  POSITIVE\n",
       "2  techinflo lead #angular development company in...  POSITIVE\n",
       "3  playlist blurry kookheon yuvin begin jaehwan l...  POSITIVE\n",
       "4  play street orphan lethal google play apart mo...  POSITIVE\n",
       "5  blessed cake welcome heaven like play death da...  POSITIVE"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_df = df.loc[df['Label'] == 'POSITIVE']\n",
    "positive_df = positive_df.drop_duplicates(subset=['Text'], keep='first').head(10387)\n",
    "positive_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text     10387\n",
       "Label    10387\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>late thanks #raspberrypi #arduino</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>artificial intelligence datum measure patient ...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>weill family foundation announce public privat...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>guys like actively drive awareness team like</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>artificial intelligence #ai attention press in...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text     Label\n",
       "1                   late thanks #raspberrypi #arduino  NEGATIVE\n",
       "7   artificial intelligence datum measure patient ...  NEGATIVE\n",
       "8   weill family foundation announce public privat...  NEGATIVE\n",
       "15       guys like actively drive awareness team like  NEGATIVE\n",
       "19  artificial intelligence #ai attention press in...  NEGATIVE"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_df = df.loc[df['Label'] == 'NEGATIVE']\n",
    "negative_df = negative_df.drop_duplicates(subset=['Text'], keep='first')\n",
    "negative_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text     9516\n",
       "Label    9516\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>trust #ai</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>people like like twitter toxic anonymously gro...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>data solutions analytic tools help businesses ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>data optimize #marketing spend #blog #seo</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>look like google play organic urls serp list find</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text    Label\n",
       "10                                          trust #ai  NEUTRAL\n",
       "11  people like like twitter toxic anonymously gro...  NEUTRAL\n",
       "12  data solutions analytic tools help businesses ...  NEUTRAL\n",
       "13          data optimize #marketing spend #blog #seo  NEUTRAL\n",
       "16  look like google play organic urls serp list find  NEUTRAL"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral_df = df.loc[df['Label'] == 'NEUTRAL']\n",
    "neutral_df = neutral_df.drop_duplicates(subset=['Text'], keep='first').head(10387)\n",
    "neutral_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text     10387\n",
       "Label    10387\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>order public truly feel change future #ai brin...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>techinflo lead #angular development company in...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>playlist blurry kookheon yuvin begin jaehwan l...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>play street orphan lethal google play apart mo...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>blessed cake welcome heaven like play death da...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Label\n",
       "0  order public truly feel change future #ai brin...  POSITIVE\n",
       "2  techinflo lead #angular development company in...  POSITIVE\n",
       "3  playlist blurry kookheon yuvin begin jaehwan l...  POSITIVE\n",
       "4  play street orphan lethal google play apart mo...  POSITIVE\n",
       "5  blessed cake welcome heaven like play death da...  POSITIVE"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([positive_df, negative_df, neutral_df])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text     30290\n",
       "Label    30290\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>think project interest #tele</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>late online advertise daily ^_new_^~*_dawn_33*...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>40.0 discount select item essort 2019 supply c...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>raspibox rail enclosure raspberry available #r...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>chance lisa representative rome</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Label\n",
       "0                       think project interest #tele   NEUTRAL\n",
       "1  late online advertise daily ^_new_^~*_dawn_33*...  NEGATIVE\n",
       "2  40.0 discount select item essort 2019 supply c...   NEUTRAL\n",
       "3  raspibox rail enclosure raspberry available #r...  POSITIVE\n",
       "4                    chance lisa representative rome   NEUTRAL"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/large_tech.csv\", sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/large_tech.csv\", sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>think project interest #tele</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>late online advertise daily ^_new_^~*_dawn_33*...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>40.0 discount select item essort 2019 supply c...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>raspibox rail enclosure raspberry available #r...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>chance lisa representative rome</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Label\n",
       "0                       think project interest #tele   NEUTRAL\n",
       "1  late online advertise daily ^_new_^~*_dawn_33*...  NEGATIVE\n",
       "2  40.0 discount select item essort 2019 supply c...   NEUTRAL\n",
       "3  raspibox rail enclosure raspberry available #r...  POSITIVE\n",
       "4                    chance lisa representative rome   NEUTRAL"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['Text', 'Label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model=None, output_dir=None, n_iter=20, n_texts=2000):\n",
    "    if model is not None:\n",
    "        # load existing spaCy model\n",
    "        nlp = spacy.load(model)\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        # Create blank Language class\n",
    "        nlp = spacy.blank('en')\n",
    "        print(\"Created new model\")\n",
    "\n",
    "    # Add the text classifier to the pipeline if it doesn't exist\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if 'textcat' not in nlp.pipe_names:\n",
    "        textcat = nlp.create_pipe('textcat')\n",
    "        nlp.add_pipe(textcat, last=True)\n",
    "    # Otherwise, get it, so we can add labels to it\n",
    "    else:\n",
    "        textcat = nlp.get_pipe('textcat')\n",
    "\n",
    "    # Add label to text classifier\n",
    "    textcat.add_label('POSITIVE')\n",
    "    textcat.add_label('NEGATIVE')\n",
    "    textcat.add_label('NEUTRAL')\n",
    "\n",
    "    (train_texts, train_cats), (dev_texts, dev_cats) = load_data(limit=n_texts)\n",
    "    print(\"Using {} examples ({} training, {} evaluation)\"\n",
    "          .format(n_texts, len(train_texts), len(dev_texts)))\n",
    "    train_data = list(zip(train_texts,\n",
    "                          [{'cats': cats} for cats in train_cats]))\n",
    "\n",
    "    # Get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\n",
    "    \n",
    "    # Only train textcat by disabling other pipes\n",
    "    with nlp.disable_pipes(*other_pipes):\n",
    "        optimizer = nlp.begin_training()\n",
    "        print(\"Training the model...\")\n",
    "        print('{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}'.format('No.', 'LOSS', 'P', 'R', 'F'))\n",
    "        for i in range(n_iter):\n",
    "            losses = {}\n",
    "            # Batch up the examples using spaCy's minibatch\n",
    "            batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(texts, annotations, sgd=optimizer, drop=0.2,\n",
    "                           losses=losses)\n",
    "            \n",
    "            with textcat.model.use_params(optimizer.averages):\n",
    "                # Evaluate on the dev data split off in load_data()\n",
    "                scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n",
    "            print('{0}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}\\t{4:.3f}'  # print a simple table\n",
    "                  .format(i, losses['textcat'], scores['textcat_p'],\n",
    "                          scores['textcat_r'], scores['textcat_f']))\n",
    "\n",
    "    if output_dir is not None:\n",
    "        output_dir = Path(output_dir)\n",
    "        if not output_dir.exists():\n",
    "            output_dir.mkdir()\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(tokenizer, textcat, texts, cats):\n",
    "    docs = (tokenizer(str(text)) for text in texts)\n",
    "    tp = 1e-8  # True positives\n",
    "    fp = 1e-8  # False positives\n",
    "    fn = 1e-8  # False negatives\n",
    "    tn = 1e-8  # True negatives\n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        gold = cats[i]\n",
    "        for label, score in doc.cats.items():\n",
    "            if label not in gold:\n",
    "                continue\n",
    "            if score >= 0.5 and gold[label] >= 0.5:\n",
    "                tp += 1.\n",
    "            elif score >= 0.5 and gold[label] < 0.5:\n",
    "                fp += 1.\n",
    "            elif score < 0.5 and gold[label] < 0.5:\n",
    "                tn += 1\n",
    "            elif score < 0.5 and gold[label] >= 0.5:\n",
    "                fn += 1\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {'textcat_p': precision, 'textcat_r': recall, 'textcat_f': f_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(limit=0, split=0.8):\n",
    "    # Partition off part of the train data for evaluation\n",
    "    cats = []\n",
    "    for y in df['Label']:\n",
    "        if (y == 'NEGATIVE'):\n",
    "            cats.append({ 'POSITIVE': 0, 'NEGATIVE': 1, 'NEUTRAL': 0 })\n",
    "        elif (y == 'POSITIVE'):\n",
    "            cats.append({ 'POSITIVE': 1, 'NEGATIVE': 0, 'NEUTRAL': 0 })\n",
    "        else:\n",
    "            cats.append({ 'POSITIVE': 0, 'NEGATIVE': 0, 'NEUTRAL': 1 })\n",
    "\n",
    "    split = int(len(df['Text'].values) * split)\n",
    "    return (df['Text'][:split], cats[:split]), (df['Text'][split:], cats[split:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new model\n",
      "Using 30000 examples (24232 training, 6058 evaluation)\n",
      "Training the model...\n",
      " No. \tLOSS \t  P  \t  R  \t  F  \n",
      "0\t23.464\t0.898\t0.888\t0.893\n",
      "1\t6.765\t0.931\t0.925\t0.928\n",
      "2\t4.425\t0.940\t0.935\t0.938\n",
      "3\t2.959\t0.950\t0.949\t0.949\n",
      "4\t2.386\t0.954\t0.952\t0.953\n",
      "5\t3.577\t0.959\t0.957\t0.958\n",
      "6\t1.395\t0.962\t0.961\t0.961\n",
      "7\t1.156\t0.962\t0.961\t0.961\n",
      "8\t0.960\t0.962\t0.961\t0.961\n",
      "9\t0.889\t0.962\t0.959\t0.960\n",
      "10\t0.655\t0.964\t0.961\t0.963\n",
      "11\t0.671\t0.964\t0.961\t0.962\n",
      "12\t0.564\t0.963\t0.961\t0.962\n",
      "13\t0.514\t0.962\t0.962\t0.962\n",
      "14\t0.504\t0.963\t0.963\t0.963\n",
      "15\t0.452\t0.965\t0.963\t0.964\n",
      "16\t0.496\t0.964\t0.964\t0.964\n",
      "17\t0.483\t0.965\t0.963\t0.964\n",
      "18\t0.412\t0.963\t0.963\t0.963\n",
      "19\t0.376\t0.964\t0.963\t0.963\n",
      "Saved model to text_cnn_models\\en_large_model\n"
     ]
    }
   ],
   "source": [
    "main(model=None, output_dir=\"text_cnn_models/en_large_model\", n_iter=20, n_texts=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'text_cnn_models/en_large_model'\n",
    "\n",
    "nlp = spacy.load(model)\n",
    "\n",
    "def predict_test(text):\n",
    "    test_text = clean_sentence(text)\n",
    "    doc = nlp(test_text)\n",
    "    print(text)\n",
    "    print(doc.cats)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@RedHat Unfortunate name. When I hear Red Hat I think MAGA. Sorry\n",
      "{'POSITIVE': 0.00033866288140416145, 'NEGATIVE': 0.999250590801239, 'NEUTRAL': 0.0031462963670492172}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test(\"@RedHat Unfortunate name. When I hear Red Hat I think MAGA. Sorry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Want to win 50000 DOGECOINS Free? Register with only 2 clicks! https://t.co/CgpuxohQDe - #crypto #bitcoin #giveaway... https://t.co/ieTGdXvI2D\n",
      "{'POSITIVE': 0.993719220161438, 'NEGATIVE': 0.00018795632058754563, 'NEUTRAL': 0.011711373925209045}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test(\"Want to win 50000 DOGECOINS Free? Register with only 2 clicks! https://t.co/CgpuxohQDe - #crypto #bitcoin #giveaway... https://t.co/ieTGdXvI2D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfortunately, nowadays fake accounts are common cases. @Revain_org is trying to fight it with AI, blockchain and r... https://t.co/xicIgcpzc3\n",
      "{'POSITIVE': 0.000712521024979651, 'NEGATIVE': 0.9994379878044128, 'NEUTRAL': 0.0012712617171928287}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test(\"Unfortunately, nowadays fake accounts are common cases. @Revain_org is trying to fight it with AI, blockchain and r... https://t.co/xicIgcpzc3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @BuucketHe4d: oh crap just deleted my entire blockchain there's no undo button wtf\n",
      "{'POSITIVE': 0.0015812794445082545, 'NEGATIVE': 0.9977349042892456, 'NEUTRAL': 0.0015919844154268503}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test(\"RT @BuucketHe4d: oh crap just deleted my entire blockchain there's no undo button wtf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holy fuck this is insane #COINBASE! I just received 2.68 #btc! Anyone can join, not much left!!! https://t.co/rt2z9osiVd\n",
      "{'POSITIVE': 0.00021646602544933558, 'NEGATIVE': 0.9996576309204102, 'NEUTRAL': 0.0007877248572185636}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test(\"holy fuck this is insane #COINBASE! I just received 2.68 #btc! Anyone can join, not much left!!! https://t.co/rt2z9osiVd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @OriginalFunko: Gears of War meets Funko is available for download now on iOS, Android and Windows 10 PC! Have you playe...\n",
      "{'POSITIVE': 0.9646284580230713, 'NEGATIVE': 0.0018142142798751593, 'NEUTRAL': 0.026635361835360527}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test(\"RT @OriginalFunko: Gears of War meets Funko is available for download now on iOS, Android and Windows 10 PC! Have you playe...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great cheat sheet\n",
      "{'POSITIVE': 0.9985173344612122, 'NEGATIVE': 4.971263842890039e-05, 'NEUTRAL': 0.004032211843878031}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test(\"great cheat sheet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ['How too many choices is having a negative impact on adoption of containerized environments https://t.co/d69sLOyIpq... https://t.co/MpkUTTlpH8',\n",
    " \"@conhaining @EmmaWedekind Docker has been dicker, cocker... it's the worst.\",\n",
    " \"Docker is the worst. I'm wasting another morning trying to figure out what they broke since the last time I had to... https://t.co/SmXHLXJvwB\",\n",
    " 'RT @arthurlutz: https://t.co/31GAFFni4n: Postmortem of failed Docker registry move https://t.co/EDaEu4bQ3t\\n\\n--docker --debian --registry --appe...',\n",
    " 'RT @utollwi VMware Rejects False Choice of Kubernetes Vs. Virtual Machines | Light Reading https://t.co/SDqlANXPyi... https://t.co/92en94AT00',\n",
    " 'RT @proudboffin: Netflix discovers severe --kubernetes HTTP/2 vulnerabilities  https://t.co/PMu8Oyg5qc --DevOps',\n",
    " 'Cloud Container Attack Tool: a new tool used to leverage Docker for attacks against AWS ECS and ECR https://t.co/LiJiDEzFEx',\n",
    " '@type__error Murder weapon: a blunt, heavy Docker container.',\n",
    " 'Netflix found a vulnerability in kubernetes which exposes your server to DOS attack, time to upgrade to the latest... https://t.co/agxIoKCE2c',\n",
    " '\"Error response from daemon: Bad response from Docker engine\"',\n",
    " \"@HoloMarkeD I get it's simple but I've been struggling so much to get the endpoint inside the docker image to work... https://t.co/WQidrKAcaI\",\n",
    " \"If you've made a docker container whose job is to launch other docker containers. You're doing it wrong.\",\n",
    " 'Severe Flaws in Kubernetes Expose All Servers to DoS Attacks https://t.co/ExnfpUh6i1\\n--Kubernetes --dos --server',\n",
    " 'Seeing errors on your cluster on a Monday is not a good week starter\\n\\n--rancher20\\n--kubernetes... https://t.co/06E6tW2J6m',\n",
    " '@Docker is destroying containerization',\n",
    " 'Based on the grief as of late, it seems that Docker is now squarely in the trough of disillusionment. \\n\\nhttps://t.co/lHEAZNtaOP',\n",
    " 'Docker in Production: A History of Failure - https://t.co/4e0Q0kSjcy https://t.co/KDjQSqSEPB',\n",
    " '@nicolakabar @Zaqloub @Docker Thks @nicolaka We solved it in the end but I think it was a bad combination of part o... https://t.co/mR87x3Ohhc',\n",
    " 'Day6, after break:\\n\\nHacked on and off on a problem with docker and bash, for a work project. Does that count?\\nWell,... https://t.co/jrFzWj9QQn',\n",
    " 'Severe --Flaws in --Kubernetes Expose All --Servers to --DoS Attacks https://t.co/LPwHRez98P https://t.co/TjRysTNxbH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How too many choices is having a negative impact on adoption of containerized environments https://t.co/d69sLOyIpq... https://t.co/MpkUTTlpH8\n",
      "{'POSITIVE': 0.0014383037341758609, 'NEGATIVE': 0.9931908249855042, 'NEUTRAL': 0.006273929495364428}\n",
      "\n",
      "\n",
      "@conhaining @EmmaWedekind Docker has been dicker, cocker... it's the worst.\n",
      "{'POSITIVE': 0.00018426570750307292, 'NEGATIVE': 0.9997240900993347, 'NEUTRAL': 0.0009085693163797259}\n",
      "\n",
      "\n",
      "Docker is the worst. I'm wasting another morning trying to figure out what they broke since the last time I had to... https://t.co/SmXHLXJvwB\n",
      "{'POSITIVE': 0.0002861627144739032, 'NEGATIVE': 0.9995036125183105, 'NEUTRAL': 0.0011003677500411868}\n",
      "\n",
      "\n",
      "RT @arthurlutz: https://t.co/31GAFFni4n: Postmortem of failed Docker registry move https://t.co/EDaEu4bQ3t\n",
      "\n",
      "--docker --debian --registry --appe...\n",
      "{'POSITIVE': 0.00021541534806601703, 'NEGATIVE': 0.9996819496154785, 'NEUTRAL': 0.0017360051861032844}\n",
      "\n",
      "\n",
      "RT @utollwi VMware Rejects False Choice of Kubernetes Vs. Virtual Machines | Light Reading https://t.co/SDqlANXPyi... https://t.co/92en94AT00\n",
      "{'POSITIVE': 0.8790310025215149, 'NEGATIVE': 0.01377122662961483, 'NEUTRAL': 0.08672600984573364}\n",
      "\n",
      "\n",
      "RT @proudboffin: Netflix discovers severe --kubernetes HTTP/2 vulnerabilities  https://t.co/PMu8Oyg5qc --DevOps\n",
      "{'POSITIVE': 0.00232429220341146, 'NEGATIVE': 0.00029113265918567777, 'NEUTRAL': 0.9995359182357788}\n",
      "\n",
      "\n",
      "Cloud Container Attack Tool: a new tool used to leverage Docker for attacks against AWS ECS and ECR https://t.co/LiJiDEzFEx\n",
      "{'POSITIVE': 0.004996899981051683, 'NEGATIVE': 0.0002721621422097087, 'NEUTRAL': 0.9995474219322205}\n",
      "\n",
      "\n",
      "@type__error Murder weapon: a blunt, heavy Docker container.\n",
      "{'POSITIVE': 0.005131773184984922, 'NEGATIVE': 0.9953328967094421, 'NEUTRAL': 0.0011865032138302922}\n",
      "\n",
      "\n",
      "Netflix found a vulnerability in kubernetes which exposes your server to DOS attack, time to upgrade to the latest... https://t.co/agxIoKCE2c\n",
      "{'POSITIVE': 0.0002573970996309072, 'NEGATIVE': 0.9996174573898315, 'NEUTRAL': 0.0017093736678361893}\n",
      "\n",
      "\n",
      "\"Error response from daemon: Bad response from Docker engine\"\n",
      "{'POSITIVE': 0.004979145713150501, 'NEGATIVE': 0.00032643857412040234, 'NEUTRAL': 0.9978031516075134}\n",
      "\n",
      "\n",
      "@HoloMarkeD I get it's simple but I've been struggling so much to get the endpoint inside the docker image to work... https://t.co/WQidrKAcaI\n",
      "{'POSITIVE': 0.014391870237886906, 'NEGATIVE': 0.014212634414434433, 'NEUTRAL': 0.978484034538269}\n",
      "\n",
      "\n",
      "If you've made a docker container whose job is to launch other docker containers. You're doing it wrong.\n",
      "{'POSITIVE': 0.0002919732069130987, 'NEGATIVE': 0.999648928642273, 'NEUTRAL': 0.00115765945520252}\n",
      "\n",
      "\n",
      "Severe Flaws in Kubernetes Expose All Servers to DoS Attacks https://t.co/ExnfpUh6i1\n",
      "--Kubernetes --dos --server\n",
      "{'POSITIVE': 0.013141434639692307, 'NEGATIVE': 0.19257321953773499, 'NEUTRAL': 0.7522554993629456}\n",
      "\n",
      "\n",
      "Seeing errors on your cluster on a Monday is not a good week starter\n",
      "\n",
      "--rancher20\n",
      "--kubernetes... https://t.co/06E6tW2J6m\n",
      "{'POSITIVE': 0.9980921149253845, 'NEGATIVE': 0.00012275076005607843, 'NEUTRAL': 0.004701994825154543}\n",
      "\n",
      "\n",
      "@Docker is destroying containerization\n",
      "{'POSITIVE': 0.0007952788728289306, 'NEGATIVE': 0.9974709749221802, 'NEUTRAL': 0.00292376521974802}\n",
      "\n",
      "\n",
      "Based on the grief as of late, it seems that Docker is now squarely in the trough of disillusionment. \n",
      "\n",
      "https://t.co/lHEAZNtaOP\n",
      "{'POSITIVE': 0.0013110701693221927, 'NEGATIVE': 0.9979380965232849, 'NEUTRAL': 0.008115054108202457}\n",
      "\n",
      "\n",
      "Docker in Production: A History of Failure - https://t.co/4e0Q0kSjcy https://t.co/KDjQSqSEPB\n",
      "{'POSITIVE': 0.00016291867359541357, 'NEGATIVE': 0.9997740387916565, 'NEUTRAL': 0.0011099242838099599}\n",
      "\n",
      "\n",
      "@nicolakabar @Zaqloub @Docker Thks @nicolaka We solved it in the end but I think it was a bad combination of part o... https://t.co/mR87x3Ohhc\n",
      "{'POSITIVE': 0.004555043298751116, 'NEGATIVE': 0.0033183107152581215, 'NEUTRAL': 0.9967479705810547}\n",
      "\n",
      "\n",
      "Day6, after break:\n",
      "\n",
      "Hacked on and off on a problem with docker and bash, for a work project. Does that count?\n",
      "Well,... https://t.co/jrFzWj9QQn\n",
      "{'POSITIVE': 0.002213780302554369, 'NEGATIVE': 0.009256815537810326, 'NEUTRAL': 0.9928152561187744}\n",
      "\n",
      "\n",
      "Severe --Flaws in --Kubernetes Expose All --Servers to --DoS Attacks https://t.co/LPwHRez98P https://t.co/TjRysTNxbH\n",
      "{'POSITIVE': 0.00285076885484159, 'NEGATIVE': 0.024215254932641983, 'NEUTRAL': 0.9822601675987244}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in test_data:\n",
    "    predict_test(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_classification_1",
   "language": "python",
   "name": "text_classification_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
